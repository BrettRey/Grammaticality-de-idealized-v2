% !TEX TS-program = xelatex
\documentclass[12pt,letterpaper]{article}

% ===========================
% BASIC PACKAGES
% ===========================
\usepackage[british]{babel}
\usepackage[final]{microtype}
\usepackage{amsmath,amssymb}
\numberwithin{equation}{section}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{float}
\usepackage{xspace}
\usepackage{tikz}
\usetikzlibrary{calc,positioning,arrows.meta,fit,backgrounds,shapes.geometric}
\usepackage{fontspec}
\setmainfont{EB Garamond}[Numbers=OldStyle,Ligatures=TeX]
\newfontfamily\ipafont{Charis SIL}
\newcommand{\ipa}[1]{{\ipafont #1}}
\providecommand{\liningnums}[1]{{\addfontfeatures{Numbers=Lining}#1}}
\setmonofont{Inconsolata}[Scale=MatchLowercase]

% ===========================
% PAGE LAYOUT
% ===========================
\usepackage[
  letterpaper,
  inner=1.25in,
  outer=1in,
  top=1in,
  bottom=1.25in,
  marginparwidth=0.6in,
]{geometry}

% ===========================
% HEADINGS
% ===========================
\usepackage{titlesec}
\titleformat{\section}{\normalfont\scshape}{\llap{\thesection\quad}}{0pt}{}
\titleformat{\subsection}{\normalfont\scshape}{\thesubsection\quad}{0pt}{}
\titleformat{\subsubsection}{\normalfont}{\thesubsubsection\quad}{0pt}{}
\titleformat{\paragraph}[runin]{\normalfont\scshape}{\theparagraph}{1em}{}
\titlespacing*{\section}{0pt}{2ex plus 1ex minus .2ex}{1ex plus .2ex}
\titlespacing*{\subsection}{0pt}{1.5ex plus 1ex minus .2ex}{0.5ex plus .2ex}
\titlespacing*{\subsubsection}{0pt}{1ex plus 0.5ex minus .1ex}{0.3ex plus .1ex}
\titlespacing*{\paragraph}{0pt}{1ex plus 0.5ex minus .1ex}{1em}

% ===========================
% RUNNING HEADS
% ===========================
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\small\scshape\leftmark}
\fancyhead[R]{\small\thepage}
\setlength{\headheight}{26pt}
\addtolength{\topmargin}{-12.4pt}
\renewcommand{\headrulewidth}{0pt}

% ===========================
% COLOURS & HYPERLINKS
% ===========================
\usepackage{xcolor}
\definecolor{linkmaroon}{RGB}{128,0,32}
\usepackage{hyperref}
\hypersetup{
  colorlinks=true,
  linkcolor=linkmaroon,
  citecolor=linkmaroon,
  urlcolor=linkmaroon,
  pdftitle={The asterisk de-idealized},
  pdfauthor={Brett Reynolds},
}

% ===========================
% QUOTATIONS
% ===========================
\usepackage[style=american]{csquotes}

% ===========================
% SEMANTIC MACROS
% ===========================
\newcommand{\term}[1]{\textsc{#1}}
\newcommand{\mention}[1]{\textit{#1}}
\newcommand{\mentionh}[1]{⟨#1⟩}
\newcommand{\olang}[1]{\textit{#1}}
\newcommand{\abbr}[1]{\textsc{#1}}
\newcommand{\eg}{e.g.\,\xspace}
\newcommand{\ie}{i.e.\,\xspace}


% ===========================
% JUDGEMENT MARKERS (TEXT-MODE SAFE)
% ===========================
\newcommand{\judgesep}{\kern-0.15em}
\newcommand{\ungram}[1]{*\judgesep#1}
\newcommand{\marg}[1]{?\judgesep#1}
\newcommand{\odd}[1]{\#\judgesep#1}

% ===========================
% LINGUISTIC EXAMPLES
% ===========================
\usepackage{langsci-gb4e}
\makeatletter
\@ifundefined{noautomath}{}{\noautomath}
\makeatother

% ===========================
% BIBLIOGRAPHY
% ===========================
\usepackage[backend=biber,style=apa,natbib=true,doi=true,isbn=false,url=true]{biblatex}
\addbibresource{refs.bib}
\newcommand{\posscite}[1]{\citeauthor{#1}'s (\citeyear{#1})}
\usepackage{orcidlink}

% ===========================
% TITLE
% ===========================
\title{The asterisk de-idealized:\\Looking back at grammaticality, moving forward with conditioned stability}
\author{Brett Reynolds \orcidlink{0000-0003-0073-7195}\\Humber Polytechnic \& University of Toronto\\\href{mailto:brett.reynolds@humber.ca}{brett.reynolds@humber.ca}}
\date{}

\begin{document}
\maketitle

\begin{abstract}
The asterisk has done foundational work in theoretical linguistics, but it also hides a persistent conflation. The same diacritic is used to mark strings that defeat structural analysis, structurally viable utterances whose values don't stabilize under the constraints of an interpreted situation, interpretable forms that still aren't in the community's repertoire, and cases that are grammatically well-formed but feel unacceptable for reasons of processing or ideology. This article argues that the resulting competence--performance--usage triangulation hasn't resolved the impasse because grammaticality has been asked to answer several distinct questions at once.

Moving forward, I propose a minimal state theory that reconceptualizes grammaticality as conditioned stability of form--value relations within communicative situations. Grammatical status depends on (i) mapping viability, (ii) interpretive coherence, and (iii) repertoire status. Distinguishing grammatical status from the feeling of ungrammaticality makes principled sense of classic dissociations between acceptability ratings and repertoire membership. The proposal yields operational diagnostics for separating coherence failures from repertoire exclusion, motivates an opportunity-normalized notion of negative evidence, and states concrete conditions under which the framework would be disconfirmed.
\end{abstract}

\noindent Keywords: grammaticality; acceptability; form--value relations; norms; preemption; processing; communicative situation

\section{Introduction}

Every competent speaker of English knows that \ungram{\mention{Can the have running}} is impossible, but the source of this certainty is still not settled. What, exactly, is being asserted when an utterance is labelled \term{ungrammatical}? Consider the following cluster:

\ea \label{ex:cluster}
\ea \ungram{\mention{Can the have running?}}\label{ex:nonsense}
\ex \mention{Colorless green ideas sleep furiously.}\label{ex:cgi} \autocite{chomsky1957}
\ex \ungram{\mention{I've finished it yesterday.}}\label{ex:pp-yesterday}
\ex \marg{\mention{I saw Joan, a friend of whose was visiting.}}\label{ex:whose}
\ex \mention{The bread the baker the apprentice helped made is delicious.}\label{ex:center}
\ex \textbf{A:} \mention{How old are you?}\quad \textbf{B:} \ungram{\mention{I have 25 years.}}\label{ex:age}
\ex \ungram{\mention{Which did you buy car?}}\label{ex:lbe}
\z\z

These items share the folk verdict that \enquote{something's wrong}, but they don't share a single type of failure. Example (\ref{ex:nonsense}) defeats structural analysis, while (\ref{ex:cgi}) is structurally impeccable but conceptually bizarre, even if a construal can be recovered. (\ref{ex:pp-yesterday}) is interpretively transparent but clashes in temporal value: tense and modifier pull in different directions. For many speakers, (\ref{ex:whose}) is not confidently rejected so much as judged marginal or uncertain in the repertoire. (\ref{ex:center}) is often rejected in spontaneous use but becomes acceptable once a parse is stabilized, suggesting a processing-driven illusion. (\ref{ex:age}) is viable and interpretable but isn't in the repertoire of the relevant English norm-centres, despite being ordinary in French and Spanish. (\ref{ex:lbe}) is short and interpretable but treated as categorically excluded.


In short, the asterisk has been doing at least four jobs: marking structural crash (\ref{ex:nonsense}), marking interpretive incoherence (\ref{ex:pp-yesterday}), marking repertoire exclusion (\ref{ex:age}), (\ref{ex:lbe}), and marking the feeling of anomaly driven by processing or ideology (\ref{ex:center}). That heterogeneity is the phenomenon.

The history of grammaticality theory can be read as a sequence of attempts to compress such heterogeneity into a single explanatory core. Formal approaches treated grammaticality as categorical well-formedness; processing accounts treated gradience as performance; usage-based theories treated acceptability as the shadow of frequency and entrenchment; sociolinguistics treated grammaticality as norm-relative; experimental syntax refined measurement but didn't settle what's being measured. The result is a familiar triangulation in which the same data is alternately explained away as \enquote{competence}, \enquote{performance}, or \enquote{usage}, often with little agreement on what would count as decisive evidence \autocite{schutze2016, sprouse2013}.

This article is a contribution to the \textit{Journal of Linguistics} section \enquote{Looking Back, Moving Forward}. Looking back, I argue that the impasse persists because grammaticality has been asked to do the work of multiple distinct questions at once. Moving forward, I propose a minimal state theory that separates those questions, thereby restoring empirical vulnerability. The core proposal is that grammaticality is \term{conditioned stability} of form--value relations\footnote{I use \term{value} for what a form conventionally contributes~-- primarily meaning, but extending to phonological and distributional regularities. Value is relational and contrastive: defined by opposition within a system, not by speaker intention \autocite{saussure1916}.} within a communicative situation: grammatical status depends on (i)~mapping viability (whether an expression-shape admits a well-typed structural analysis), (ii)~interpretive coherence (whether the values encoded stabilize under the constraints live in the situation), and (iii)~repertoire status (whether the form--value relation~-- especially at the operator stratum~-- is treated as a legitimate option in the relevant norm-centre). The same decomposition also clarifies how the \term{feeling of ungrammaticality} arises as a metacognitive signal whose sources include, but aren't exhausted by, grammatical status; this distinction explains why some constructions feel ungrammatical while being licit, and why some illicit constructions escape detection \autocite{Fanselow2021}.

The structure is as follows. Section~\ref{sec:lookingback} diagnoses the impasse by reviewing what the asterisk has been made to mean. Section~\ref{sec:impasse} isolates the multiple questions that have been collapsed into one label. Section~\ref{sec:movingforward} introduces the state theory: conditioning states, the three constitutive quantities, and the stability score. Section~\ref{sec:profiles} works through diagnostic profiles that the model predicts. Section~\ref{sec:evidence} addresses evidence and measurement, including a worked opportunity proxy. Section~\ref{sec:future} frames key questions for future research. Section~\ref{sec:falsify} states what would count against the framework. Readers who want the core model quickly can focus on \S\ref{sec:movingforward}.\ref{sec:quantities}--\ref{sec:stability}, Table~\ref{tab:profiles}, and \S\ref{sec:falsify}.

\section[Looking back]{Looking back: what the asterisk has been made to mean}\label{sec:lookingback}

The modern theoretical role of grammaticality was shaped by the mid-century identification of grammar with a formal system generating a set of well-formed expressions. In this tradition, grammaticality is a categorical membership fact: a string is grammatical iff it's generated by the grammar \autocite{chomsky1957}. This view captures the hard edge of cases like (\ref{ex:nonsense}), where the system crashes before any stable analysis is available. It also provides a clean division of labour: semantics and pragmatics interpret outputs; performance systems realize them.

The cost of this idealization is that it forces the field to treat gradience as epiphenomenal. The competence--performance distinction \autocite{chomsky1965} allowed formal theory to preserve categorical grammar by relocating variability to processing and attention, but the move is methodologically hazardous: once invoked, it can immunize the grammar from counterevidence by labelling inconvenient data as performance noise \autocite[71]{schutze2016}. Much subsequent work can be read as a search for principled ways to reintroduce gradience without abandoning the insight that some failures are genuinely categorical.

Meaning, coherence, and the limits of well-formedness present a second theme. Chomsky's (\ref{ex:cgi}) was designed to show that structural well-formedness doesn't reduce to semantic plausibility. That point remains foundational: a theory that equates grammaticality with \enquote{interpretability} will misclassify many robust structural constraints. But (\ref{ex:cgi}) also revealed a complementary fact: humans routinely accept structurally well-formed utterances whose values are conceptually odd, while rejecting other utterances whose intended interpretation is transparent. This tension motivated a long tradition of work linking acceptability to interpretive pressures, including semantic motivation for constraints \autocite{lakoff1971, mccawley1968} and constructional meaning \autocite{goldberg1995constructions}.

These traditions didn't establish that meaning replaces grammar; rather, they showed that the stability of interpretation is itself a locus of constraint. An utterance may be structurally viable but fail because the values encoded by its parts can't be reconciled under the constraints that are live in a situation.
The present perfect plus \mention{yesterday} in (\ref{ex:pp-yesterday}) is a canonical case \autocite[140--141]{huddleston2002}: the intended meaning is obvious, but the morphosyntactic temporal value conflicts with the adjunct anchoring. Conversely, in English at least, many lexical clashes are tolerated as long as they don't implicate morphosyntactic value.

Processing and the reallocation of gradience constitute a third response. If grammar is categorical but judgements are gradient, one obvious move is to treat gradience as a function of processing. The processing literature has supplied a large inventory of robust effects~-- dependency locality, interference, garden-path reanalysis~-- that depress ratings and slow reading times for structures that are otherwise analyzable \autocite{gibson2000, GrodnerGibson2005}. Classic centre-embedding examples like (\ref{ex:center}) are often treated as the poster children: they are grammatical in the sense of analyzable and interpretable, but they trigger strong negative responses because incremental parsing is strained.

Processing explanations, though, don't exhaust the landscape. Certain constructions remain sharply rejected even when short and interpretable, and even when repeated exposure doesn't improve ratings. The literature on satiation and adaptation was partly motivated by precisely this need \autocite{snyder2000grammaticality, Snyder2022, reynolds2025hpcbook}: some degraded structures improve with exposure, others don't, and the difference can't be reduced to length or memory load alone. While processing accounts for why such structures feel ungrammatical, it doesn't, by itself, constitute a theory of grammatical status.

Usage, norms, and the social life of grammaticality provide a fourth strand. Usage-based approaches shifted attention to the role of frequency and entrenchment: speakers learn the distributions of forms, and those distributions shape what feels acceptable \autocite{bybee2006, bybee2010, reynolds2026lbe}. A key advance in this tradition is the recognition of \term{preemption}: a form can be rejected because a competitor is consistently selected in the same niche, even if the discarded form remains structurally possible \autocite{Goldberg2011}. The contrast between \mention{I'm 25 years old} and \ungram{\mention{I have 25 years}} in English illustrates the point: the latter is transparent and structurally viable, but is systematically excluded from the repertoire of the relevant norm-centres.

Sociolinguistic accounts, meanwhile, emphasize that grammaticality resides not in the abstract properties of a language, but in a community's normed repertoire \autocite{labov1972}. Indexical values attached to forms can shift what a situation admits to the repertoire, and speakers routinely disagree about what counts as \enquote{the} grammar because they construe different norm-centres as relevant \autocite{Silverstein1976, Eckert2012}. Far from an embarrassment, this constitutes part of the phenomenon. The problem's that, in much theoretical practice, norm-relativity's treated as a complication external to grammar rather than as a constitutive feature of what grammatical status amounts to.

\section[The impasse diagnosed]{The impasse diagnosed: three questions collapsed into one label}\label{sec:impasse}

Rather than noise, the heterogeneity in (\ref{ex:cluster}) is structural. Four things have been collapsed, but only three are constitutive of grammatical status itself; the fourth~-- the feeling of ungrammaticality~-- is a distinct phenomenon that needs to be separated. Grammaticality theory has repeatedly attempted to treat grammatical status as a unified phenomenon when it is, in fact, the intersection of three distinct questions.

First, structural viability. Some inputs fail because no structural analysis is available that yields a well-typed morphosyntactic representation. In such cases, the failure is categorical and doesn't depend on meaning, social norm-centres, or processing effort; the analysis crashes. Example (\ref{ex:nonsense}) is emblematic: the category sequence prevents the construction of a viable constituent structure.

Treating this failure mode as real is non-negotiable: without it, the notion of grammar loses its basic explanatory purchase. The mistake lies in elevating this single prerequisite into the definition of grammaticality itself.

Second, interpretive coherence. Many strings are structurally viable but unstable in value. Sometimes the instability is semantic (temporal alignment, argument structure satisfaction); sometimes pragmatic or information-structural (topic/focus fit); sometimes indexical (social meaning clashes with footing). The common thread lies in the stability of a dominant construal under the constraints that are live in the relevant situation, rather than in a folk notion of \enquote{meaningfulness}.

Example (\ref{ex:pp-yesterday}) illustrates: the intended interpretation is obvious, but the morphosyntactic value encoded by the present perfect conflicts with the temporal anchoring provided by \mention{yesterday}. The result is interpretive instability grounded in conventional form--value relations, rather than structural nonsense.

Third, repertoire status. A third class of cases are structurally viable and interpretively coherent, but rejected because they aren't in the community's repertoire. Here the role of usage and norms is constitutive: the community hasn't conventionalized the relevant form--value relation as a legitimate option under the norm-centres that define the communicative situation.

Example (\ref{ex:age}) is again emblematic. The form isn't nonsensical, and it's interpretable. Its rejection is a fact about English community conventions, not about universal cognitive limits. The same form is licit in other languages, demonstrating that the relevant factor is repertoire status, not viability or coherence.

A fourth label deserves separation: the feeling of ungrammaticality. The three components above are constitutive for grammatical status. But speakers' judgements also reflect a \term{feeling of ungrammaticality}: a metacognitive negative signal triggered by instability or high repair cost. This feeling is an important object of study, but it isn't identical to grammaticality. It yields false positives, where licit constructions feel bad, and false negatives, where illicit constructions pass undetected \autocite{Fanselow2021}. Equating ratings with grammatical status invites conceptual confusion.

Four concepts need to be kept apart. \term{Appropriateness} is the genus: the fit between a form and the context in which it's used. \term{Grammaticality} is one species of appropriateness~-- the coupling between grammatical form and the values it conventionally expresses. It has a fact of the matter: either the form--value relation is in the repertoire for the relevant conditioning state or it isn't~-- even when that fact isn't directly accessible to measurement.\footnote{The distinction between ontological fact and epistemic access is developed in \textcite[ch.~5]{reynolds2025hpcbook}, which argues that category boundaries are structurally determinate but located at thresholds we cannot finitely specify; gradient judgments arise from discrete categories filtered through processing noise, not from gradient membership.} \term{Acceptability} is the measurement channel: how speakers rate utterances, informed by grammatical status but also by processing factors, repair costs, and ideological filtering. \term{Correctness} is the prescriptive overlay: what gatekeepers enforce, what gets codified and moralized~-- often an ideologized version of one variety's appropriateness norms imposed as if universal. A predictable objection to the framework below is that $C_t$ (repertoire status) merely relabels prescriptive correctness. The answer is no: correctness concerns what should be enforced; repertoire status is a constitutive fact about what a norm-centred population actually treats as a legitimate resource. Enforcement can distort evidence, but the repertoire state isn't the prescription \autocite[for parallel distinctions]{pullum2019-normativity}.

The remainder of the paper proposes a minimal state theory that makes these distinctions explicit, thereby clarifying what it is for an utterance type to be grammatical \emph{in a communicative situation}.

\section[Moving forward: conditioned stability]{Moving forward: grammaticality as conditioned stability of form--value relations}\label{sec:movingforward}

The state theory commits to just three things: analyzability, stability of construal, and repertoire status~-- each relativized to a construed situation. The notation that follows is bookkeeping, not a new philosophical burden.

\subsection{Conditioning states and communicative situations}

Consider a speaker who says \mention{I seen it}. In a classroom presentation, this is likely to be heard as ungrammatical; at lunch with friends, it may pass without comment. The string hasn't changed; what's changed is which norm-centre is in play and what's at stake. This is what conditioning captures.

Let $c$ be a \term{conditioning state}: a construed communicative situation together with whatever norm-centre is treated as relevant \autocite{wiese2023}. The point isn't to reify $c$ as a fixed external context; interlocutors can misalign about which $c$ is in force, and $c$ can be renegotiated. The modelling commitment is simply that grammatical status is always assessed relative to some such conditioning.

Rather than an optional sociolinguistic add-on, this move is the minimal way to state the empirical fact that grammars are socially situated repertoires: the same speaker can treat different resources as in-repertoire in different situations, and different speakers can rationally disagree about repertoire membership when they construe different norm-centres. This is the core of the realist commitment: grammaticality isn't an abstract property of the string, but a measurable state of the relation between form, value, and agents in a constructed situation.

The conditioning state $c$ can be decomposed into at least three anchors \autocite{reynolds2026varieties}:
\begin{itemize}
\item \textsc{Situation} ($S$): the here-and-now interactional frame~-- activity type, medium, footing, institutional context.
\item \textsc{Ascription} ($A$): what the speaker is treated as~-- the social categories assigned by self and others, which condition expectations about baseline repertoire.
\item \textsc{Identification} ($I$): whose norms are being oriented to~-- the reference population the speaker treats as the standard for what counts as legitimate.
\end{itemize}
Together these yield a conditioning vector $c\approx\langle S,A,I\rangle$. Situational stakes are modelled separately as part of the decision regime: holding $c$ fixed, stakes tune the criterion $\tau$ (and therefore the categorical verdict $G_t$) rather than directly conditioning $\mathsf{map}$, $K$, or $C_t$. For compactness I continue to write $\tau(c)$, but where stakes is manipulated independently the intended dependence is $\tau(c,\text{stakes})$. The decomposition matters because apparent disagreement about grammaticality often reflects misalignment in $A$ or $I$ rather than genuine conflict about the state of the form--value relation. The same token can be processed as dialectal (in-repertoire under one ascription) or as an error (out-of-repertoire under a different norm-centre), depending on which conditioning anchors the listener infers. This is why the classroom/lunch contrast for \mention{I seen it} isn't just about formality ($S$); it's also about whose norms are in play ($I$) and what categorization the listener assigns to the speaker ($A$).

\subsection{Three constitutive quantities}\label{sec:quantities}

For an utterance type $u$ in conditioning state $c$ at time $t$, define three state quantities.

The first quantity is mapping viability. Let $\mathsf{map}(u,c)\in\{0,1\}$ be a binary indicator of whether there exists at least one viable morphosyntactic analysis for $u$ in $c$ for which there's a well-typed representation (where 1 is viable and 0 isn't). $\mathsf{map}$ is intended to capture genuine analyzability failure and only that. It's the categorical prerequisite highlighted by the well-formedness tradition~-- the \enquote{entry ticket} to the system~-- but it doesn't on its own guarantee either interpretive coherence or repertoire membership. Many ungrammatical strings remain easily parsed and \enquote{interpreted} in a folk sense.

The second quantity is interpretive coherence. Let $K(u,c)\in[0,1]$\footnote{The curly braces $\{0,1\}$ denote a two-member set (exactly 0 or 1); the square brackets $[0,1]$ denote the continuous interval from 0 to 1 inclusive.} represent the stability of interpretation: the degree to which the utterance yields a dominant, non-contradictory construal under the constraints live in $c$ (ranging from 0, complete instability, to 1, perfect coherence). Formally, $K$ can be modelled as concentration of a distribution over candidate construals; for present purposes, the important point is that $K$ is distinct from $\mathsf{map}$. Structural viability doesn't guarantee coherence.

The third quantity is repertoire status. Let $C_t(u,c)\in[0,1]$ be the population-level posterior probability that the form--value relation $u$ is in the community's repertoire for $c$: the probability that an individual drawn from the relevant norm-centred population treats $u$ as a legitimate resource rather than as an error, performance slip, or alien form (where 1 represents universal acceptance and 0 indicates total exclusion). This quantity is related to what usage-based work calls entrenchment, but it's explicitly conditioned on $c$ and includes normative dimensions that pure entrenchment doesn't capture. While $C_t$ is informed by frequency, it represents inferred repertoire membership rather than a simple tally of token occurrences.

$C_t$ is where norms live. It's also where many apparently categorical exclusions can be located without positing hard representational bans: a form can be structurally viable and interpretable while being near-universally excluded from the repertoire in a given situation.

The $S$/$A$/$I$ decomposition of $c$ introduced above clarifies what fixes \enquote{the community} for a given evaluation. Identification ($I$) is the natural anchor for whose repertoire counts in $C_t$: the reference population is whoever the speaker is orienting to. Situation ($S$) and stakes are the natural anchors for the decision regime $\tau(c)$: high-stakes institutional contexts raise the threshold. Ascription ($A$) explains a major source of apparent inconsistency: the same string can be treated as in-repertoire when attributed to one ascribed group and as an error when attributed to another, even if the underlying variety grammar is the same. That isn't a change in $\mathsf{map}$ or $K$; it's a change in how listeners map tokens to norm-centres.

\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{@{}lp{4.5cm}p{5.5cm}@{}}
\toprule
\textbf{Symbol} & \textbf{What it tracks} & \textbf{Diagnostic evidence} \\
\midrule
$\mathsf{map}$ & Structural analyzability (0/1) & Parse failure, no stable category assignment \\
$K$ & Interpretive coherence (0--1) & Paraphrase dispersion, construal instability \\
$C_t$ & Repertoire status (0--1) & Production rates, \enquote{would you say this?}, corpus frequency normalized by opportunity \\
\bottomrule
\end{tabular}
\caption{The three constitutive quantities at a glance.}
\label{tab:symbols}
\end{table}

\subsection{A stability score and a membership predicate}\label{sec:stability}

Define a graded stability score:
\begin{equation}\label{eq:stability}
\widetilde{G}_t(u,c)=\mathsf{map}(u,c)\cdot K(u,c)\cdot C_t(u,c)\in[0,1].
\end{equation}
This multiplicative scoring means that if any single component is zero~-- if the mapping fails, if interpretation is impossible, or if the form isn't in the community's repertoire~-- the entire relation is ungrammatical. Stability underwrites gradience: lowering any component reduces the overall score.

In plain terms: the product rule says that being in-repertoire can't make up for being incoherent, and being perfectly coherent can't make up for being out-of-repertoire. Deficits compound rather than average out.

This decomposition reflects a broader organization of linguistic infrastructure. Expression-shape constraints (phonotactics, morphotactics) regulate whether an utterance is recognizable as a token of the system; their violation yields \enquote{not a word}. Operator-like constraints~-- closed-paradigm contrasts that configure public update, allocate participant roles, and authorize uptake~-- are targeted by $K$ (for value coherence) and $C_t$ (for community repertoire); their violation yields \enquote{you can't say that}. Payload resources (open-class lexicon, indexical stance) remain negotiable and extensible; their misuse invites clarification or social judgment, not structural rejection. The stability score $\widetilde{G}_t$ integrates across these levels: a form that crashes at any level is unstable, but the \emph{type} of instability differs diagnostically.

Communities also often treat grammaticality as a categorical membership fact: either a resource is in the repertoire or not. Model this by thresholding:
\begin{equation}\label{eq:membership}
G_t(u,c)=\mathbb{I}\!\left[\widetilde{G}_t(u,c)\ge \tau(c)\right],
\end{equation}
where $\tau(c)$ is a situation-specific decision criterion. The point is that $\tau(c)$ is a property of how strict the situation is about what counts as \enquote{in} the repertoire. High-stakes institutional contexts can set a high threshold; low-stakes in-group contexts can set a lower one.

To illustrate: in a classroom presentation, using a stigmatized dialectal form risks being marked down; the threshold for \enquote{grammatical enough} rises. At lunch with friends, the same form may index solidarity; the threshold drops. Same form, same $\widetilde{G}$, different verdicts.

A concern is that $\tau(c)$ might immunize the theory if it can vary freely. Two constraints matter. First, $\tau(c)$ isn't construction-specific: it's fixed for a conditioning state and therefore shifts the boundary for \emph{all} utterance types evaluated in that state. Adjusting $\tau$ to rescue a single problematic case entails collateral predictions for a broad set of anchor items. Second, $\tau(c)$ can be motivated by a standard decision-theoretic rationale in which classification losses differ by situation. Let $L_{\textsc{fa}}(c)$ be the loss of treating an item as in-repertoire when it is not, and $L_{\textsc{fr}}(c)$ the loss of treating an item as not-in-repertoire when it is. A natural constraint is
\[
\tau(c)=\frac{L_{\textsc{fa}}(c)}{L_{\textsc{fa}}(c)+L_{\textsc{fr}}(c)}.
\]
This ties $\tau$ to independently characterizable properties of the communicative situation (stakes, institutional norms, gatekeeping pressure). Empirically, $\tau(c)$ can be estimated by calibrating participants on an anchor set spanning clear in-repertoire and clear not-in-repertoire items for the target $c$, rather than being tuned post hoc to accommodate the construction under dispute.

This formalizes an intuition that's often stated informally but rarely built into the state theory: what counts as \enquote{grammatical} for practical purposes depends on the decision regime of the situation, not just the resource itself. Figure~\ref{fig:minimal} summarizes the minimal architecture.

\begin{figure}[t]
\centering
\def\BoxH{1.2cm} % ratings box height
\def\RowSep{1.7cm} % main-row centre-to-centre distance
\def\HalfRow{0.85cm} % half-row offset
\def\Col{2.7cm} % main column spacing
\def\Dx{0.5cm} % slight right-offset for half-row nodes

\begin{tikzpicture}[
  latent/.style={circle, draw, line width=0.6pt,
    minimum size=\BoxH, font=\normalsize, inner sep=0pt},
  observed/.style={rectangle, rounded corners=5pt, draw,
    line width=0.6pt, minimum height=\BoxH, minimum width=1.9cm,
    font=\small, inner sep=6pt, align=center},
  every edge/.style={draw, line width=0.5pt, -{Stealth[length=4pt, width=3pt]}},
]

  % === Row baselines (subset of full grid) ===
  \coordinate (r3) at (0,0);
  \path (r3) ++(0,-\RowSep) coordinate (r4);
  \path (r4) ++(0,-\RowSep) coordinate (r5);

  % === Column baselines ===
  \coordinate (c1) at (0,0);
  \path (c1) ++(\Col,0) coordinate (c2);
  \path (c2) ++(\Col,0) coordinate (c3);
  \path (c3) ++(\Col,0) coordinate (c4);

  % === Nodes ===
  \node[observed] (tau) at (c1 |- r3) {$\tau(c)$};
  \node[latent] (map) at (c2 |- r3) {$\mathsf{map}$};
  \node[latent] (K) at (c3 |- r3) {$K$};
  \node[latent] (Ct) at (c4 |- r3) {$C_t$};

  \node[latent] (Gtilde) at (c3 |- r4) {$\widetilde{G}_t$};
  \node[observed,anchor=west] (ratings) at ($(Ct.west)+(0,-\RowSep)$) {ratings};
  \node[observed,anchor=west] (proc) at ($(ratings.east)+(\Dx,0)$) {\shortstack{processing\\costs}};

  \node[latent] (Gt) at (c3 |- r5) {$G_t$};

  % === Edges ===
  \path (map) edge (Gtilde);
  \path (K) edge (Gtilde);
  \path (Ct) edge (Gtilde);

  \path (Gtilde) edge (Gt);
  \path (tau) edge (Gt);

  \path (Gtilde) edge (ratings);
  \path (proc) edge (ratings);

\end{tikzpicture}
\caption{The minimal state architecture. Grammatical status $\widetilde{G}_t$ combines mapping, coherence, and repertoire status. Acceptability ratings reflect $\widetilde{G}_t$ filtered through processing costs, while categorical membership $G_t$ involves a situation-specific threshold $\tau(c)$.}
\label{fig:minimal}
\end{figure}

\subsection{Why this combination rule isn't decorative}\label{sec:combination}

(If you accept the decomposition, the point of this subsection is just to show that the multiplication yields discriminable interaction predictions. Skim if pressed.)

The three-way decomposition is the theoretical commitment; the choice of a specific combination operator is a modelling decision. But the operator should be constrained by desiderata that make it empirically non-trivial.

First, the core is non-compensatory: mapping failure, catastrophic incoherence, or categorical repertoire exclusion should each be sufficient to drive grammatical status to zero in the relevant $c$. This excludes simple weighted sums as a model of grammatical status, since they permit a high value on one dimension to compensate for near-zero on another. Second, the graded score should reflect compounding instability: two moderate deficits should typically be worse than either deficit alone. Third, the operator should be monotone in each argument, and it should allow a transparent generalization to relative weighting if later work justifies it.

Several standard operations meet the non-compensatory constraint. The minimum operator,
\[
\widetilde{G}^{\min}_t(u,c)=\min\{\mathsf{map}(u,c),K(u,c),C_t(u,c)\},
\]
treats the weakest link as decisive. This makes a clear prediction: once one component is identified as the bottleneck, further degradation elsewhere shouldn't matter for the objective score. At the other extreme, a weighted sum predicts systematic compensation:
\[
\widetilde{G}^{\Sigma}_t(u,c)=w_{\mathsf{map}}\mathsf{map}+w_KK+w_CC_t,
\]
which is often plausible as a model of subjective ratings but is a poor fit for a state theory of grammatical status precisely because it allows a community to \enquote{make up for} incoherence by repertoire status alone.

The product rule adopted in \eqref{eq:stability},
\[
\widetilde{G}^{\times}_t(u,c)=\mathsf{map}(u,c)\cdot K(u,c)\cdot C_t(u,c),
\]
is the simplest operator that's non-compensatory and compounding. It also has a useful interpretive property: in log-space, the components contribute additively ($\log \widetilde{G}=\log \mathsf{map}+\log K+\log C_t$), which aligns naturally with an evidence-accumulation picture in which distinct sources of instability contribute independent penalties. If future work motivates differential weighting, the product generalizes straightforwardly to a weighted geometric form, $\mathsf{map}\cdot K^{\alpha}\cdot C_t^{\beta}$, with $\alpha,\beta>0$.

The choice among $\min$ and $\times$ is empirically discriminable. Consider a factorial manipulation that independently lowers coherence and repertoire status while holding mapping constant: for the same morphosyntactic frame, introduce a mild value-clash (lowering $K$) and, independently, present the construction under a norm-centre that treats it as non-native or marginal (lowering $C_t$).\footnote{The repertoire-status manipulation can be implemented by norm-centre framing (ingroup/dialect/resource vs error) and by register framing (a shift in $S$, hence in $c$, which can in turn shift $C_t$). Stakes framing is predicted primarily to shift the decision criterion $\tau$.} The minimum rule predicts that once either $K$ or $C_t$ is the bottleneck, the second manipulation shouldn't further depress the objective score; the product rule predicts a systematic interaction (compounding), since the combined manipulation reduces stability more than either alone. This is a substantive prediction about the structure of the state space, not a restatement of the verbal story.

An information-theoretic perspective clarifies why this matters. The multiplicative structure has a natural interpretation in terms of how linguistic contrasts contribute to interpretation. Some form--value relations occupy small, closed paradigms but cause large downstream consequences: clause type constrains which responses are relevant; polarity flips entailment relations; case and agreement constrain role assignment. These relations function as control settings~-- protocol headers rather than payload content~-- carrying few bits in themselves but causing large entropy reduction in the space of licit interpretations \autocite{shannon1948,coverthomas2006}. A wrong value doesn't merely produce a surprising concept combination; it disrupts the mapping from form to publicly recognizable update. This is why a short, interpretable utterance like (\ref{ex:pp-yesterday}) can trigger categorical rejection: the violation targets infrastructure, not content. The product rule captures this asymmetry: degradation in control-like dimensions ($\mathsf{map}$, $K$ for operator-relevant constraints, $C_t$ for high-opportunity paradigms) compounds rapidly, while payload-level infelicities remain negotiable.

\textit{Empirical upshot:} $K \times C_t$ manipulations should compound under the product rule; if they don't, the operator is wrong even if the decomposition stands.

\subsection{Separating coherence from repertoire status: operational criteria}\label{sec:KvsC}

A recurring worry is that coherence failure $K\approx 0$ and repertoire exclusion $C_t\approx 0$ may collapse into one another, since both yield low stability. The separation requires distinct measurement signatures.

\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{@{}p{5.5cm}p{5.5cm}@{}}
\toprule
\textbf{Low $K$ (coherence failure)} & \textbf{Low $C_t$ (repertoire exclusion)} \\
\midrule
Construal unstable; speakers disagree on meaning & Construal stable; speakers agree on meaning \\
Paraphrase dispersion high & Paraphrase agreement high \\
Repair-heavy, effortful interpretation & Readily interpretable \\
\enquote{What does that even mean?} & \enquote{I know what you mean, but we don't say that} \\
\addlinespace
\textit{Diagnostics:} paraphrase tasks, construal variability, RT to inference questions & \textit{Diagnostics:} production probability, \enquote{would you say this?}, corpus frequency / opportunity \\
\bottomrule
\end{tabular}
\caption{Separating coherence from repertoire status: predicted contrasts.}
\label{tab:KvsC}
\end{table}

These diagnostics cut across the tempting verbal contrast between \enquote{values can't be reconciled} and \enquote{the community doesn't accept the reconciliation}. In practice, the decisive question is whether the source of degradation is interpretive dispersion or repertoire exclusion.

This is why (\ref{ex:pp-yesterday}) is a useful but non-trivial diagnostic. Many speakers can recover the intended meaning of \mention{I've finished it yesterday} with little difficulty, which pushes it toward a low-$C_t$ profile (repertoire exclusion of a specific tense--adverb pairing) rather than a pure low-$K$ profile. On the other hand, if an experimental design reveals systematic competition between two construals (a present-perfect reading vs a coerced simple-past reading), then the same item will show low $K$ by exhibiting dispersion in paraphrase and inference tasks even when participants are instructed to treat the form as a legitimate dialectal resource. The framework is falsifiable here: it predicts that the $K$-diagnosis and the $C$-diagnosis diverge in their measurement signatures.

\subsection{Grammaticality versus the feeling of ungrammaticality}

The state theory above defines grammatical status via $\widetilde{G}_t$ and $\tau(c)$. Speakers' ratings often track a different quantity: a subjective ungrammaticality signal driven by low stability, processing costs, and ideological overlays.

A useful way to characterize this signal is as \term{inverse conditioning}. If speakers condition production on $S$, $A$, and $I$, then listeners can infer those conditioning anchors from observed forms~-- Bayes' theorem running in reverse. The feeling of ungrammaticality is naturally tied to surprisal relative to the listener's inferred conditioning model: hearing a form that's low-probability under the $c$ the listener thinks is in force triggers the signal. Processing costs and ideological overlays layer on top, but the core input to the detector is $-\log P(u\mid c)$. This framing has two methodological payoffs. First, it gives a principled bridge from ratings to a measurement channel: ratings are observations of a detector whose input includes surprisal plus processing costs, not direct observations of $C_t$. Second, it makes the later discussion of language models less risky: LMs approximate something like $P(u\mid \text{context})$ for some training-conditioned mixture of $c$'s, which is naturally closer to \enquote{detector input} than to \enquote{truth about $G_t$}.

This distinction predicts systematic dissociations:

\begin{itemize}
\item Licit but degraded: $\mathsf{map}=1$, $K$ high, $C_t$ high, but processing costs depress ratings (classic centre embedding).
\item Illicit but unnoticed: $\mathsf{map}=1$ and the intended meaning is salient, so the ungrammaticality signal is weak even when a relevant coherence constraint is violated (agreement attraction and other slips in complex structures; \citealt{wagers2009agreement}).
\end{itemize}

Equating acceptability ratings with grammatical status conflates a state claim with a measurement channel \autocite[ch.~5]{reynolds2025hpcbook}. The methodological consequence is that claims about $G_t$ should be supported by converging indicators, with ratings treated as evidence primarily about the ungrammaticality signal and only indirectly about repertoire status.

\section{Diagnostic profiles: what different failures look like}\label{sec:profiles}

Beyond being definitional, the value of a state theory lies in the diagnostic profiles it predicts. The decomposition in (\ref{eq:stability}) yields a compact typology of recurrent instability modes. The typology reflects that an utterance can be structurally well-mapped and easily \enquote{interpreted} in a folk sense while remaining ungrammatical due to coherence failure or repertoire exclusion.

\begin{table}[H]
\centering
\begin{tabular}{@{}p{4.2cm}p{7.8cm}@{}}
\toprule
Profile & Canonical signature\\
\midrule
$\mathsf{map}=0$ & Structural crash; categorical rejection; no amount of context stabilizes meaning (\ref{ex:nonsense}).\\[4pt]
$\mathsf{map}=1$, $K\approx 0$ & Value incompatibility; intended meaning might be guessable, but conventional form--value constraints in $c$ block stabilization (\ref{ex:pp-yesterday}).\\[4pt]
$\mathsf{map}=1$, $K$ high, $C_t\approx 0$ & Repertoire exclusion; interpretable but treated as not in the repertoire; often cross-linguistically variable (\ref{ex:age}, \ref{ex:lbe}).\\[4pt]
$\mathsf{map}=1$, $K$ high, $C_t$ low/uncertain & Rarity/indeterminacy; weak consensus; high variance across speakers (\ref{ex:whose}).\\[4pt]
$\mathsf{map}=1$, $K$ high, $C_t$ high, but high processing cost & Illusory ungrammaticality; improves with guidance; ratings track repair cost more than status (\ref{ex:center}).\\
\bottomrule
\end{tabular}
\caption{Recurrent diagnostic profiles as regions of the state space.}
\label{tab:profiles}
\end{table}

To see the table at work, revisit the opening cluster. \mention{Can the have running} (\ref{ex:nonsense}) is row~1: $\mathsf{map}=0$. \mention{I've finished it yesterday} (\ref{ex:pp-yesterday}) is row~2: the string parses, but temporal values clash ($K$ low). \mention{I have 25 years} (\ref{ex:age}) is row~3: fully interpretable, but English doesn't have it in repertoire ($C_t\approx 0$). \mention{A friend of whose} (\ref{ex:whose}) is row~4: the opportunity set is small, so speakers are uncertain rather than categorical \autocite{reynolds2024whose}. \mention{The bread the baker\ldots} (\ref{ex:center}) is row~5: licit but processing-heavy, producing illusory ungrammaticality. The table isn't ornamental; it partitions the puzzle set.

Two contrasts are key for the future research agenda: stable repertoire exclusion versus rarity, and objective status versus felt ungrammaticality.

\subsection{Stable repertoire exclusion versus rarity}

A raw corpus absence is compatible with two very different states. A construction can be rare because the opportunity set is tiny, leaving speakers with little evidence either way; or it can be rare because, despite a large opportunity set, it's systematically preempted by competitors, driving repertoire status toward zero. The independent relative genitive in (\ref{ex:whose}) plausibly belongs to the first class for many speakers: the configuration that would make it useful is itself rare, so the absence of tokens doesn't straightforwardly imply categorical exclusion.

\begin{sloppypar}
Left-branch extraction in (\ref{ex:lbe}) behaves differently. The communicative niche is common, competitors are available (\mention{Which car did you buy?}), and speakers show robust categorical rejection. This profile is analyzed as near-zero repertoire status in the relevant norm-centres, consistent with a preemption-based trajectory \autocite{Goldberg2011,reynolds2026lbe}. In this view, categoricality needn't be located in $\mathsf{map}$: the intended analysis can be available and interpretation can be coherent once stipulated, while the community treats the relation as excluded from the repertoire.
\end{sloppypar}

\subsection{Illusory ungrammaticality and misattribution}

Processing-driven illusions illustrate why the feeling of ungrammaticality can't be equated with grammatical status. Centre embedding (\ref{ex:center})'s analyzable and interpretable, but incremental parsing strains working memory and dependency integration, triggering strong negative affect \autocite{Gibson2026}. Similarly, garden-path items can feel nonsensical until reanalyzed:

\ea \mention{The old man the boats.} \autocite{ritchie1984}\label{ex:old-man}
\z

A first-pass parse yields nonsense; reanalysis yields a coherent, licit structure. In such cases, ratings track repair difficulty, not repertoire status \autocite[cf.][on acceptability as an introspective report of processing cost]{Gibson2026}. Conversely, illicit structures can pass unnoticed when meaning is compelling, yielding false negatives \autocite{pullum2009}.

The repair system provides converging evidence. When repair does occur, mismatches targeting operator-like dimensions \autocite{reynolds2026operators}~-- tense errors, agreement failures, clause-type confusions~-- are predicted to elicit open-class repair initiation (\mention{what?}, \mention{who did it?}) and explicit rejection, because they disrupt the publicly accountable control settings on which uptake depends. Mismatches targeting payload or indexical dimensions are predicted to elicit stance negotiation and accommodation (\mention{did you mean...?}, \mention{why are you talking like that?}), because the utterance's update potential remains intact even when its content or social positioning is problematic. This asymmetry is independent of the feeling of ungrammaticality: a processing-heavy but licit structure may feel terrible without triggering the repair profile associated with genuine operator failure.

The state theory predicts such dissociations whenever the ungrammaticality signal pools multiple sources of difficulty.

\section[Evidence and measurement]{Evidence and measurement: what it would take to test the state theory}\label{sec:evidence}

A \enquote{moving forward} programme has to specify what would count as evidence. The constitutive variables suggest a principled division of labour among data types (Figure~\ref{fig:medium}).

\begin{figure}[t]
\centering
\def\BoxH{1.2cm}
\def\RowSep{1.7cm}
\def\HalfRow{0.85cm}
\def\Col{2.7cm}
\def\Branch{2.6cm}
\def\Dx{0.5cm}

\begin{tikzpicture}[
  latent/.style={circle, draw, line width=0.6pt,
    minimum size=\BoxH, font=\normalsize, inner sep=0pt},
  observed/.style={rectangle, rounded corners=5pt, draw,
    line width=0.6pt, minimum height=\BoxH, minimum width=1.9cm,
    font=\small, inner sep=6pt, align=center},
  every edge/.style={draw, line width=0.5pt, -{Stealth[length=4pt, width=3pt]}},
]

  % === Rows/Cols ===
  \coordinate (r1) at (0,0);
  \path (r1) ++(0,-\RowSep) coordinate (r2);
  \path (r2) ++(0,-\RowSep) coordinate (r3);
  \path (r3) ++(0,-\RowSep) coordinate (r4);
  \path (r4) ++(0,-\RowSep) coordinate (r5);

  \coordinate (c1) at (0,0);
  \path (c1) ++(\Col,0) coordinate (c2);
  \path (c2) ++(\Col,0) coordinate (c3);
  \path (c3) ++(\Col,0) coordinate (c4);

  % === Nodes ===
  % Row 3: State layer
  \node[observed] (tau) at (c1 |- r3) {$\tau(c)$};
  \node[latent] (map) at (c2 |- r3) {$\mathsf{map}$};
  \node[latent] (K) at (c3 |- r3) {$K$};
  \node[latent] (Ct) at (c4 |- r3) {$C_t$};

  % Row 4: Stability & Ratings
  \node[latent] (Gtilde) at (c3 |- r4) {$\widetilde{G}_t$};
  \node[observed,anchor=west] (ratings) at ($(Ct.west)+(0,-\RowSep)$) {ratings};

  % C_t indicators (aligned relative to ratings/Ct)
  \node[observed,anchor=west] (prod) at ($(ratings.east)+(\Dx,2*\RowSep)$) {\shortstack{production\\probability}};
  \node[observed,anchor=west] (corpus) at ($(prod.west)+(0,\RowSep)$) {\shortstack{corpus freq.\\/\,opportunity}};
  \node[observed,anchor=west] (repair) at ($(prod.west)+(0,-\RowSep)$) {\shortstack{repair\\behaviour}};

  % Row 4/5: Ratings modifiers
  \node[observed,anchor=west] (proc) at ($(ratings.east)+(\Dx,0)$) {\shortstack{processing\\costs}};
  \node[observed,anchor=west] (ideo) at ($(ratings.east)+(\Dx,-\RowSep)$) {\shortstack{ideological\\filtering}};

  % Row 5: Membership
  \node[latent] (Gt) at (c3 |- r5) {$G_t$};

  % === Edges ===
  % State -> Stability
  \path (map) edge (Gtilde);
  \path (K) edge (Gtilde);
  \path (Ct) edge (Gtilde);

  % Threshold -> Membership
  \path (Gtilde) edge (Gt);
  \path (tau) edge (Gt);

  % Ratings channel
  \path (Gtilde) edge (ratings);
  \path (proc) edge (ratings);
  \path (ideo) edge (ratings);

  % Indicator channels (generative: Latent -> Observed)
  \path (Ct) edge (prod);
  \path (Ct) edge (corpus.south west);
  \path (Ct) edge (repair);

\end{tikzpicture}
\caption{The medium-resolution architecture. Adds observable indicators for $C_t$ and ideological filtering on ratings. Arrows represent generative influence; inference runs in the opposite direction.}
\label{fig:medium}
\end{figure}

For mapping viability, evidence comes from analyzability: whether speakers can assign a stable category structure, whether repairs consistently fail, and whether comprehension collapses even under supportive contexts. Structural crash cases are rare but diagnostically clean.

For coherence, evidence comes from interpretive stability under controlled manipulations of the relevant constraints (temporal alignment, argument structure, information structure, indexical consistency). Here experimental pragmatics and semantics supply tools for isolating which constraints are doing the work, while corpus work can reveal conventional distributional restrictions that track those constraints.

For repertoire status, $C_t$ is latent and can't be inferred from ratings alone. It has to be estimated from converging indicators: production probability in elicitation, corpus frequency normalized by opportunity sets, repair behaviour, recognition latency, and social evaluation under explicit norm-centre manipulations. The state theory motivates an explicit measurement model for $C_t$ in which acceptability ratings are treated primarily as observations of the ungrammaticality signal, not of repertoire status.

One central challenge involves operationalizing \term{opportunity}. Preemption-based accounts require not only token counts but niche counts: how often the communicative job arises in the relevant $c$. A key empirical task for the moving-forward agenda is to develop operational definitions of niches for different constructions and to measure non-occurrence relative to those opportunities \autocite[for a corpus-based implementation using Bayesian partial pooling over construction-specific opportunity sets, see][]{reynolds2026lbe}. The next subsection sketches the logic with a simpler case.

\subsection{A worked opportunity proxy: age-stating}\label{sec:opportunity-worked}

Opportunity-normalisation is the hinge between mere corpus rarity and evidence of systematic exclusion. The general problem is that niches aren't directly annotated in corpora: we rarely observe \enquote{the speaker needed to express X} as an explicit variable. A workable starting point is to use competitor forms as a lower-bound proxy for opportunities. If speakers reliably realise a niche using an established competitor, then each observed competitor token witnesses an opportunity in which the target variant could, in principle, have been selected.

Consider (\ref{ex:age}), \ungram{\mention{I have 25 years}}, a construction with \mention{have} taking age as object. The niche is: `state a person's age in response to a direct or indirect enquiry'. Competitor realisations of this niche are easy to identify~-- all copular constructions with age as predicative complement:
(i) \mention{I'm 25};
(ii) \mention{I'm 25 years old};
(iii) \mention{I'm 25 years of age}.
Each token of (i)--(iii) witnesses an opportunity: a speaker needed to state an age and chose one of these forms.

Let $N^{\ast}$ be the competitor count in a corpus slice approximating the relevant $c$. Age-stating is common: a conversational corpus will contain thousands of tokens of (i)--(iii). If the \mention{have}-construction were in the English repertoire~-- even as a rare option~-- we'd expect to find some tokens among those thousands. We find none. That zero matters precisely because $N^{\ast}$ is large. Compare a rarer niche: if the competitor count is 50, finding zero tokens of a target variant tells us almost nothing~-- the form might simply be uncommon. The evidential force of absence scales with opportunity.

The \mention{have}-construction is entirely absent from L1 English data, despite being the productive pattern in French, Spanish, and other languages. The mapping is transparent ($\mathsf{map}$ and $K$ pose no obstacle: hearers readily interpret \mention{I have 25 years}), but $C_t \approx 0$~-- the \mention{have}-construction simply isn't part of the L1 English repertoire for this niche. Occasional tokens from L1 French speakers are predicted rather than problematic: $C_t$ is conditioned on $c$, and the speaker's linguistic identification ($I$) is part of $c$. For the L1 English community, $C_t \approx 0$; for French-L1 speakers of English, it may be substantially higher. An L1 English hearer understands the utterance without difficulty~-- $\mathsf{map}$ and $K$ are intact~-- but recognises it as outside the community repertoire. That recognition \emph{is} the low-$C_t$ judgment. The asterisk on (\ref{ex:age}) is then not a brute intuition but a consequence of low $C_t$ in a well-mapped, coherent construction~-- exactly the kind of diagnosis the model is designed to deliver.

This proxy operationalization is deliberately coarse, but it's already discriminating: it separates cases where \enquote{no tokens} is probative (large $N^{\ast}$) from cases where it isn't (small $N^{\ast}$). More generally, this is what a \enquote{moving forward} corpus programme has to provide: explicit definitions of competitor sets for niches and principled choices of corpus slices approximating $c$.

\section[Questions for future research]{Key questions for future theoretical research}\label{sec:future}

The state theory reframes several longstanding debates as tractable research questions.

How should conditioning states be operationalized? If grammaticality is conditioned, then specifying $c$ isn't optional (Figure~\ref{fig:full} shows the full conditioned architecture). Future work has to develop operational proxies for norm-centres and communicative situations: genre, medium, stance, audience design, institutional stakes, and community membership. An important prediction is that constructions whose status is driven by $C_t$ will be more sensitive to $c$-manipulation than map-failures and many coherence-failures.

What are the right objects of repertoire membership? The theory treats $u$ as an utterance type, but in practice the granularity of $u$ matters. Is \mention{gave the dog a bone} in-repertoire as a specific string, as an instance of the ditransitive construction, or as part of a broader caused-possession family? A moving-forward programme has to articulate principled criteria for individuating $u$ in a way that makes the repertoire term empirically meaningful rather than vacuous.

\begin{figure}[t]
\centering
\def\BoxH{1.2cm}
\def\RowSep{1.7cm}
\def\HalfRow{0.85cm}
\def\Col{2.7cm}
\def\Branch{2.6cm}
\def\Dx{0.5cm}

\begin{tikzpicture}[
  latent/.style={circle, draw, line width=0.6pt,
    minimum size=\BoxH, font=\normalsize, inner sep=0pt},
  observed/.style={rectangle, rounded corners=5pt, draw,
    line width=0.6pt, minimum height=\BoxH, minimum width=1.9cm,
    font=\small, inner sep=6pt, align=center},
  cond/.style={diamond, draw, line width=0.6pt, minimum size=\BoxH,
    font=\normalsize, inner sep=3pt, align=center},
  every edge/.style={draw, line width=0.5pt, -{Stealth[length=4pt, width=3pt]}},
]

  % === Rows/Cols ===
  \coordinate (r1) at (0,0);
  \path (r1) ++(0,-\RowSep) coordinate (r2);
  \path (r2) ++(0,-\RowSep) coordinate (r3);
  \path (r3) ++(0,-\RowSep) coordinate (r4);
  \path (r4) ++(0,-\RowSep) coordinate (r5);

  \coordinate (c1) at (0,0);
  \path (c1) ++(\Col,0) coordinate (c2);
  \path (c2) ++(\Col,0) coordinate (c3);
  \path (c3) ++(\Col,0) coordinate (c4);

  % === Row 1: Conditioning Anchors ===
  \node[observed] (stakes) at (c1 |- r1) {stakes};
  \node[cond] (S) at (c2 |- r1) {$S$};
  \node[cond] (A) at (c3 |- r1) {$A$};
  \node[cond] (I) at (c4 |- r1) {$I$};

  % === Row 2: c ===
  \node[latent] (c) at (c3 |- r2) {$c$};

  % === Row 3: State layer ===
  \node[observed] (tau) at (c1 |- r3) {$\tau(c)$};
  \node[latent] (map) at (c2 |- r3) {$\mathsf{map}$};
  \node[latent] (K) at (c3 |- r3) {$K$};
  \node[latent] (Ct) at (c4 |- r3) {$C_t$};

  % === Row 4: Stability & Ratings ===
  \node[latent] (Gtilde) at (c3 |- r4) {$\widetilde{G}_t$};
  \node[observed,anchor=west] (ratings) at ($(Ct.west)+(0,-\RowSep)$) {ratings};

  % C_t indicators (Generative: from Ct)
  \node[observed,anchor=west] (prod) at ($(ratings.east)+(\Dx,2*\RowSep)$) {\shortstack{production\\probability}};
  \node[observed,anchor=west] (corpus) at ($(prod.west)+(0,\RowSep)$) {\shortstack{corpus freq.\\/\,opportunity}};
  \node[observed,anchor=west] (repair) at ($(prod.west)+(0,-\RowSep)$) {\shortstack{repair\\behaviour}};

  % Row 4/5: Ratings modifiers
  \node[observed,anchor=west] (proc) at ($(ratings.east)+(\Dx,0)$) {\shortstack{processing\\costs}};
  \node[observed,anchor=west] (ideo) at ($(ratings.east)+(\Dx,-\RowSep)$) {\shortstack{ideological\\filtering}};

  % Row 5: Membership
  \node[latent] (Gt) at (c3 |- r5) {$G_t$};

  % === Edges: Conditioning ===
  \path (S) edge (c);
  \path (A) edge (c);
  \path (I) edge (c);
  \path (stakes) edge (tau);
  \path (c) edge (tau.north east);

  \path (c) edge (map);
  \path (c) edge (K);
  \path (c) edge (Ct);

  % === Edges: State -> Stability ===
  \path (map) edge (Gtilde);
  \path (K) edge (Gtilde);
  \path (Ct) edge (Gtilde);

  % === Edges: Threshold -> Membership ===
  \path (Gtilde) edge (Gt);
  \path (tau) edge (Gt);

  % === Edges: Ratings ===
  \path (Gtilde) edge (ratings);
  \path (proc) edge (ratings);
  \path (ideo) edge (ratings);

  % === Edges: Indicators ===
  \path (Ct) edge (prod);
  \path (Ct) edge (corpus.south west);
  \path (Ct) edge (repair);

\end{tikzpicture}
\caption{The full conditioned architecture. Shows how the conditioning state $c$ is constituted by situation ($S$), ascription ($A$), and identification ($I$) anchors, and how it drives the state variables. Stakes drive the threshold $\tau(c)$ independently of $c$'s content.}
\label{fig:full}
\end{figure}

What is the etiology of stable gaps? The present paper has remained mostly constitutive. The natural next step is an etiological module: a model of how $C_t(u,c)$ trajectories arise under positive evidence, error evidence, and opportunity-sensitive preemption. Instead of debating whether preemption exists, the crucial question is its effective strength across niches and how it interacts with processing difficulty and social evaluation. This is where classic \enquote{categorical} constraints become a test case: the moving-forward claim is that at least some of them can be redescribed as stable repertoire exclusion sustained by strong preemption in robust opportunity sets.

A related question is which form--value relations attract sharp repertoire boundaries in the first place. The present framework is neutral on this, but a natural hypothesis is that repertoire policing clusters around \term{operator} contrasts: closed-paradigm choices that configure public update, allocate participant roles, and constrain uptake~-- clause type, argument linking, tense--aspect where grammaticalized, evidential anchoring. If this is correct, then $C_t$ trajectories are shaped not only by opportunity mass but by the functional load of the contrast: high-entropy-reduction dimensions attract categorical policing because a wrong value causes coordination failure even when the utterance is otherwise intelligible. This reframes the \enquote{categorical vs.\ gradient} debate as a question about which dimensions of the state space are operator-like, rather than about whether gradience is real \autocite{reynolds2026operators}.

A complementary etiological resource is coordination equilibria in the sense of evolutionary game theory \autocite{oconnor2019games}. On this view, communicative situations are payoff structures, and repertoire boundaries stabilize because they solve recurring coordination problems. Some partitions become sharp and policed because category salience enables coordination: once a contrast is salient, speakers and listeners expect each other to respect it, and deviation is costly. This explains why $C_t$ can remain near zero for forms that are structurally viable and interpretable~-- the coordination equilibrium excludes them. It also explains why certain boundaries resist erosion even under exposure: the equilibrium is self-sustaining because unilateral deviation is penalised. This game-theoretic module is compatible with the constitutive framework but adds an explanation of why some gaps are stable and others drift. The threshold $\tau(c)$ fits naturally into this picture: high-stakes situations are precisely those where coordination failure is costly, and institutions often encode the expected equilibrium as explicit gatekeeping.

How should typological generalizations be interpreted? If grammatical systems are normed repertoires shaped by stability dynamics, typological regularities are naturally viewed as recurring attractors in design space rather than as exceptionless laws. The task is to identify which combinations of form--value relations are robustly stable across lineages and which are contingent on local history and norm-centres. Large-scale typology becomes evidence about the global stability landscape rather than a direct route to categorical universals.

What role should language models play? Language models are now unavoidable instruments in linguistic practice. The state theory suggests a principled way to use them without mistaking their outputs for grammatical truth. If a model is treated as a proxy for the ungrammaticality signal, it may be useful for predicting processing difficulty and surprisal-like effects; if it's treated as evidence about repertoire status, it has to be grounded in opportunity-normalized distributions and norm-centre conditioning. The resulting agenda is methodological: what, exactly, are models approximating when they mimic human judgements, and which variable in (\ref{eq:stability}) does that approximation correspond to?

\section{What would count against this framework?}\label{sec:falsify}

A framework that decomposes grammatical status into multiple components risks appearing too flexible unless each component is tied to independent evidence. The present proposal is disconfirmed, or at least seriously pressured, by any of the following patterns.

Each condition targets a specific earlier commitment: (1) targets the $K$/$C_t$ separation (\S\ref{sec:KvsC}); (2) targets the opportunity methodology (\S\ref{sec:opportunity-worked}); (3) targets conditioning and thresholds (\S\ref{sec:movingforward}.\ref{sec:stability}); (4) targets the combination rule (\S\ref{sec:combination}); (5) targets the decomposition as a whole.

\begin{enumerate}
\item If there's no measurable dissociation between coherence and repertoire status~-- if constructions diagnosed as low-$C_t$ (repertoire exclusion) systematically exhibit the same interpretive-dispersion profile as constructions diagnosed as low-$K$, and if tasks designed to separate these signatures fail across a range of phenomena~-- then the K/C distinction isn't empirically supported.

\item If opportunity-normalized absence doesn't discriminate stable gaps from rarity~-- if constructions widely treated as \enquote{categorical} don't show strong opportunity proxies via large competitor counts ($N^{\ast}$) while rare/uncertain constructions do~-- then the central methodological claim about opportunity-sensitive negative evidence is undermined.

\item If norm-centre and stakes manipulations don't affect the predicted targets, the conditioning architecture is mis-specified. The $S$/$A$/$I$ decomposition yields a specific experimental toolkit: manipulate $S$ via genre/register framing, institutional roleplay, or audience-design cues; manipulate $A$ via speaker ascription cues (biographical metadata, voice/ethnolectal markers, explicitly stated background); manipulate $I$ via explicit norm-centre orientation cues (\enquote{speaking as a member of X community}, \enquote{aiming for formal norms}, \enquote{in-group banter}); manipulate stakes via consequence framing that should shift $\tau(c)$ without necessarily shifting $C_t$. If such manipulations don't systematically shift threshold behaviour (as indexed by anchor sets) and don't preferentially affect constructions hypothesized to be repertoire-sensitive, the $S$/$A$/$I$ structure isn't just a conceptual repackaging; it's a design toolkit that tells you what counts as a clean manipulation of $c$ rather than a vague \enquote{context effect}.

\item If the combination rule makes the wrong interaction predictions~-- if factorial manipulations that independently target coherence and repertoire status show no compounding interaction where the product rule predicts one~-- then either a different non-compensatory operator is required (e.g.\ $\min$), or the assumption that the components contribute independently to objective stability is incorrect.

\item If there are robust cases of categorical exclusion with high independent evidence of repertoire membership~-- if a construction is demonstrably used productively in the relevant $c$ (high production probability and opportunity-normalized corpus rates) and yields stable construals, but is still treated as categorically ungrammatical in repertoire-membership tasks by the same population~-- then the proposal that grammatical status is constituted by repertoire status plus coherence plus mapping is incomplete.
\end{enumerate}

\begin{sloppypar}
These conditions are intentionally stated as empirical profiles rather than as verbal counterexamples, since the point is to align theoretical claims with distinct measurement channels.
\end{sloppypar}

\section{Conclusion}

Looking back, grammaticality has functioned as a foundational organizing notion in theoretical linguistics, but it has been burdened with incompatible tasks: marking structural crash, signalling coherence failure, recording community norms, and reporting subjective ungrammaticality. The resulting conceptual overloading has fuelled recurring disputes about whether data is \enquote{competence}, \enquote{performance}, or \enquote{usage}.

Moving forward, grammaticality can be reconceptualized as a state property: conditioned stability of form--value relations within a communicative situation. A minimal decomposition into mapping viability $\mathsf{map}$, interpretive coherence $K$, and repertoire status $C_t$ yields a compact diagnostic typology and clarifies why acceptability ratings are an imperfect thermometer. \begin{sloppypar}
The same framework reframes categorical exclusions as potentially emergent stable repertoire exclusion sustained by opportunity-sensitive preemption, and it motivates a concrete research agenda: operationalizing conditioning states, defining the objects of repertoire membership, measuring opportunity sets, and building convergent estimators for repertoire status that don't collapse grammatical status into subjective affect.
\end{sloppypar}

If grammaticality is to remain a useful concept for theoretical linguistics, it has to become a target of explanation rather than a presupposed label. The state theory proposed here is intended as a step in that direction: it doesn't replace existing insights about structure, meaning, processing, or norms, but is a minimal architecture that makes their interaction explicit and testable. In this, the asterisk is de-idealized: it stops being a mark of abstract ill-formedness and becomes a realist diagnostic of stability failure in a situated communicative state.

\section*{Acknowledgements}

Thanks to Peter Evans, Geoff Pullum, Muhammad Ali Khalidi, Ryan Nefdt, Irene Kosmas, and Mostafa Hasrati for comments and suggestions. Henri Kauhanen reviewed the formalization.

I used the large language models Claude 3.5 \& 4.5; ChatGPT o1 pro \& 5.2 pro; Gemini 3; and DeepSeek V3 in drafting and editing this paper.

\newpage
\begin{sloppypar}
\printbibliography[title=References]
\end{sloppypar}

\end{document}
